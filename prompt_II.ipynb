{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michellechen202212/ucb/blob/main/prompt_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHU4AL-NX4Nc"
      },
      "source": [
        "# What drives the price of a car?\n",
        "\n",
        "![](images/kurt.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4nvCnQtX4Ne"
      },
      "source": [
        "**OVERVIEW**\n",
        "\n",
        "In this application, you will explore a dataset from Kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYgBKcvuX4Ne"
      },
      "source": [
        "### CRISP-DM Framework\n",
        "\n",
        "<center>\n",
        "    <img src = images/crisp.png width = 50%/>\n",
        "</center>\n",
        "\n",
        "\n",
        "To frame the task, throughout our practical applications, we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EQgYI62X4Ne"
      },
      "source": [
        "### Business Understanding\n",
        "\n",
        "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGSdNHaJX4Nf",
        "outputId": "8e22c751-cddc-4686-e4a1-27a1b5236d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial R^2 with Linear Regression: 0.6338518845873631\n",
            "R^2 with Ridge Regression: 0.6338437540412545\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'sample_data/vehicles_cleaned_outliers_removed.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Drop rows with missing values\n",
        "data_cleaned = data.dropna()\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = data_cleaned.drop(columns=['price', 'model', 'manufacturer'])\n",
        "y = data_cleaned['price']\n",
        "\n",
        "# Select categorical and numerical features\n",
        "categorical_features = ['condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'paint_color']\n",
        "numerical_features = ['year', 'odometer']\n",
        "\n",
        "# Preprocess categorical and numerical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the pipeline with Linear Regression\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Linear Regression model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate R^2\n",
        "y_pred = pipeline.predict(X_test)\n",
        "initial_r2 = r2_score(y_test, y_pred)\n",
        "print(\"Initial R^2 with Linear Regression:\", initial_r2)\n",
        "\n",
        "# Define the pipeline with Ridge Regression for regularization\n",
        "ridge_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', Ridge(alpha=1.0))  # Regularization parameter alpha set to 1.0\n",
        "])\n",
        "\n",
        "# Train the Ridge regression model\n",
        "ridge_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate R^2 with Ridge Regression\n",
        "y_ridge_pred = ridge_pipeline.predict(X_test)\n",
        "ridge_r2 = r2_score(y_test, y_ridge_pred)\n",
        "print(\"R^2 with Ridge Regression:\", ridge_r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xp6HnzF_X4Nf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV79E6j4X4Nf",
        "outputId": "a02aecc4-76f2-4681-dd57-35e339e4fbcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial R^2 with Linear Regression: 0.6338518845873631\n",
            "R^2 with Ridge Regression: 0.6338437540412545\n",
            "Cross-Validation Results:\n",
            "Mean R^2 (Linear Regression): 0.6337\n",
            "Mean R^2 (Ridge Regression): 0.6337\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score, make_scorer\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'sample_data/vehicles_cleaned_outliers_removed.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Drop rows with missing values\n",
        "data_cleaned = data.dropna()\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = data_cleaned.drop(columns=['price', 'model', 'manufacturer'])\n",
        "y = data_cleaned['price']\n",
        "\n",
        "# Select categorical and numerical features\n",
        "categorical_features = ['condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'paint_color']\n",
        "numerical_features = ['year', 'odometer']\n",
        "\n",
        "# Preprocess categorical and numerical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the pipeline with Linear Regression\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Define the pipeline with Ridge Regression for regularization\n",
        "ridge_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', Ridge(alpha=1.0))  # Regularization parameter alpha set to 1.0\n",
        "])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Linear Regression model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate R^2\n",
        "y_pred = pipeline.predict(X_test)\n",
        "initial_r2 = r2_score(y_test, y_pred)\n",
        "print(\"Initial R^2 with Linear Regression:\", initial_r2)\n",
        "\n",
        "# Train the Ridge regression model\n",
        "ridge_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate R^2 with Ridge Regression\n",
        "y_ridge_pred = ridge_pipeline.predict(X_test)\n",
        "ridge_r2 = r2_score(y_test, y_ridge_pred)\n",
        "print(\"R^2 with Ridge Regression:\", ridge_r2)\n",
        "\n",
        "# Perform cross-validation\n",
        "# Define a custom scorer for R^2\n",
        "r2_scorer = make_scorer(r2_score)\n",
        "\n",
        "# Set up K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Reduce dataset size by taking a random sample (20% of data)\n",
        "sampled_data = data_cleaned.sample(frac=0.2, random_state=42)\n",
        "X_sampled = sampled_data.drop(columns=['price', 'model', 'manufacturer'])\n",
        "y_sampled = sampled_data['price']\n",
        "\n",
        "# Perform cross-validation with the Ridge regression pipeline on the smaller dataset\n",
        "cv_ridge_scores_sampled = cross_val_score(ridge_pipeline, X_sampled, y_sampled, cv=kf, scoring=r2_scorer)\n",
        "cv_linear_scores_sampled = cross_val_score(pipeline, X_sampled, y_sampled, cv=kf, scoring=r2_scorer)\n",
        "\n",
        "# Calculate the mean R^2 score for each model on the sampled dataset\n",
        "ridge_cv_mean_r2_sampled = cv_ridge_scores_sampled.mean()\n",
        "linear_cv_mean_r2_sampled = cv_linear_scores_sampled.mean()\n",
        "\n",
        "# Display cross-validation results\n",
        "print(\"Cross-Validation Results:\")\n",
        "print(f\"Mean R^2 (Linear Regression): {linear_cv_mean_r2_sampled:.4f}\")\n",
        "print(f\"Mean R^2 (Ridge Regression): {ridge_cv_mean_r2_sampled:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOgz_wnjX4Nf",
        "outputId": "073484b5-3846-48f5-f1c8-a232d7ea189d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial R^2 with Linear Regression: 0.6338518845873631\n",
            "R^2 with Ridge Regression: 0.6338437540412545\n",
            "MSE (Ridge Regression): 57821228.75\n",
            "RMSE (Ridge Regression): 7604.03\n",
            "Cross-Validation Results:\n",
            "Mean R^2 (Linear Regression): 0.6337\n",
            "Mean R^2 (Ridge Regression): 0.6337\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'sample_data/vehicles_cleaned_outliers_removed.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Drop rows with missing values\n",
        "data_cleaned = data.dropna()\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = data_cleaned.drop(columns=['price', 'model', 'manufacturer'])\n",
        "y = data_cleaned['price']\n",
        "\n",
        "# Select categorical and numerical features\n",
        "categorical_features = ['condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'paint_color']\n",
        "numerical_features = ['year', 'odometer']\n",
        "\n",
        "# Preprocess categorical and numerical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the pipeline with Linear Regression\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Define the pipeline with Ridge Regression for regularization\n",
        "ridge_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', Ridge(alpha=1.0))  # Regularization parameter alpha set to 1.0\n",
        "])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Linear Regression model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate R^2 for Linear Regression\n",
        "y_pred = pipeline.predict(X_test)\n",
        "initial_r2 = r2_score(y_test, y_pred)\n",
        "print(\"Initial R^2 with Linear Regression:\", initial_r2)\n",
        "\n",
        "# Train the Ridge regression model\n",
        "ridge_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate R^2 with Ridge Regression\n",
        "y_ridge_pred = ridge_pipeline.predict(X_test)\n",
        "ridge_r2 = r2_score(y_test, y_ridge_pred)\n",
        "print(\"R^2 with Ridge Regression:\", ridge_r2)\n",
        "\n",
        "# Calculate MSE and RMSE for Ridge Regression\n",
        "ridge_mse = mean_squared_error(y_test, y_ridge_pred)\n",
        "ridge_rmse = np.sqrt(ridge_mse)\n",
        "print(f\"MSE (Ridge Regression): {ridge_mse:.2f}\")\n",
        "print(f\"RMSE (Ridge Regression): {ridge_rmse:.2f}\")\n",
        "\n",
        "# Perform cross-validation\n",
        "# Define a custom scorer for R^2\n",
        "r2_scorer = make_scorer(r2_score)\n",
        "\n",
        "# Set up K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Reduce dataset size by taking a random sample (20% of data)\n",
        "sampled_data = data_cleaned.sample(frac=0.2, random_state=42)\n",
        "X_sampled = sampled_data.drop(columns=['price', 'model', 'manufacturer'])\n",
        "y_sampled = sampled_data['price']\n",
        "\n",
        "# Perform cross-validation with the Ridge regression pipeline on the smaller dataset\n",
        "cv_ridge_scores_sampled = cross_val_score(ridge_pipeline, X_sampled, y_sampled, cv=kf, scoring=r2_scorer)\n",
        "cv_linear_scores_sampled = cross_val_score(pipeline, X_sampled, y_sampled, cv=kf, scoring=r2_scorer)\n",
        "\n",
        "# Calculate the mean R^2 score for each model on the sampled dataset\n",
        "ridge_cv_mean_r2_sampled = cv_ridge_scores_sampled.mean()\n",
        "linear_cv_mean_r2_sampled = cv_linear_scores_sampled.mean()\n",
        "\n",
        "# Display cross-validation results\n",
        "print(\"Cross-Validation Results:\")\n",
        "print(f\"Mean R^2 (Linear Regression): {linear_cv_mean_r2_sampled:.4f}\")\n",
        "print(f\"Mean R^2 (Ridge Regression): {ridge_cv_mean_r2_sampled:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'sample_data/vehicles_cleaned_outliers_removed.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Drop rows with missing values\n",
        "data_cleaned = data.dropna().drop_duplicates()\n",
        "\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = data_cleaned.drop(columns=['price', 'model', 'manufacturer'])\n",
        "y = data_cleaned['price']\n",
        "\n",
        "# Select categorical and numerical features\n",
        "categorical_features = ['condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'paint_color']\n",
        "numerical_features = ['year', 'odometer']\n",
        "\n",
        "# Preprocess categorical and numerical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Define the pipeline with Ridge Regression\n",
        "ridge_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', Ridge())\n",
        "])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a grid of hyperparameters to search\n",
        "param_grid = {\n",
        "    'regressor__alpha': [0.1, 1.0, 10.0, 100.0]  # Different values for the regularization strength\n",
        "}\n",
        "\n",
        "# Set up Grid Search\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=ridge_pipeline,\n",
        "    param_grid=param_grid,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring='neg_mean_squared_error',  # Use negative MSE for optimization\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict using the best model\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "\n",
        "# Calculate MSE and RMSE\n",
        "best_mse = mean_squared_error(y_test, y_pred_best)\n",
        "best_rmse = np.sqrt(best_mse)\n",
        "\n",
        "# Output results\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(f\"Best MSE: {best_mse:.2f}\")\n",
        "print(f\"Best RMSE: {best_rmse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy7BNrITjnQf",
        "outputId": "5798f69d-7497-43c9-9c57-8cfafcb75a90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[CV] END ...............................regressor__alpha=0.1; total time=   1.1s\n",
            "[CV] END ...............................regressor__alpha=0.1; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=0.1; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=0.1; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=0.1; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=1.0; total time=   1.7s\n",
            "[CV] END ...............................regressor__alpha=1.0; total time=   1.8s\n",
            "[CV] END ...............................regressor__alpha=1.0; total time=   1.3s\n",
            "[CV] END ...............................regressor__alpha=1.0; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=1.0; total time=   1.0s\n",
            "[CV] END ..............................regressor__alpha=10.0; total time=   1.0s\n",
            "[CV] END ..............................regressor__alpha=10.0; total time=   1.0s\n",
            "[CV] END ..............................regressor__alpha=10.0; total time=   1.0s\n",
            "[CV] END ..............................regressor__alpha=10.0; total time=   1.0s\n",
            "[CV] END ..............................regressor__alpha=10.0; total time=   1.0s\n",
            "[CV] END .............................regressor__alpha=100.0; total time=   0.9s\n",
            "[CV] END .............................regressor__alpha=100.0; total time=   0.9s\n",
            "[CV] END .............................regressor__alpha=100.0; total time=   1.4s\n",
            "[CV] END .............................regressor__alpha=100.0; total time=   1.5s\n",
            "[CV] END .............................regressor__alpha=100.0; total time=   1.6s\n",
            "Best Parameters: {'regressor__alpha': 1.0}\n",
            "Best MSE: 57821228.75\n",
            "Best RMSE: 7604.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'sample_data/vehicles_cleaned_outliers_removed.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Drop rows with missing values\n",
        "data_cleaned = data.dropna()\n",
        "\n",
        "# Define features (X) and target variable (y)\n",
        "X = data_cleaned.drop(columns=['price', 'model', 'manufacturer'])\n",
        "y = data_cleaned['price']\n",
        "\n",
        "# Select categorical and numerical features\n",
        "categorical_features = ['condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'paint_color']\n",
        "numerical_features = ['year', 'odometer']\n",
        "\n",
        "# Define RMSE as a scoring metric\n",
        "def rmse_score(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "rmse_scorer = make_scorer(rmse_score, greater_is_better=False)\n",
        "\n",
        "# Preprocess categorical and numerical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Ridge Regression Pipeline\n",
        "ridge_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', Ridge())\n",
        "])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ridge Regression: Hyperparameter tuning\n",
        "ridge_param_grid = {\n",
        "    'regressor__alpha': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
        "}\n",
        "\n",
        "ridge_grid_search = GridSearchCV(\n",
        "    estimator=ridge_pipeline,\n",
        "    param_grid=ridge_param_grid,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=rmse_scorer,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "ridge_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Ridge Regression model\n",
        "best_ridge_params = ridge_grid_search.best_params_\n",
        "best_ridge_model = ridge_grid_search.best_estimator_\n",
        "\n",
        "# Test set predictions for Ridge Regression\n",
        "y_pred_ridge = best_ridge_model.predict(X_test)\n",
        "\n",
        "# RMSE for Ridge Regression\n",
        "ridge_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
        "print(\"Ridge Regression:\")\n",
        "print(\"Best Parameters:\", best_ridge_params)\n",
        "print(f\"Test RMSE: {ridge_rmse:.2f}\")\n",
        "\n",
        "# Gradient Boosting Pipeline\n",
        "gbr_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# Gradient Boosting: Hyperparameter tuning\n",
        "gbr_param_grid = {\n",
        "    'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
        "    'regressor__n_estimators': [100, 200, 300],\n",
        "    'regressor__max_depth': [3]\n",
        "}\n",
        "\n",
        "gbr_grid_search = GridSearchCV(\n",
        "    estimator=gbr_pipeline,\n",
        "    param_grid=gbr_param_grid,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=rmse_scorer,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "gbr_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Gradient Boosting model\n",
        "best_gbr_params = gbr_grid_search.best_params_\n",
        "best_gbr_model = gbr_grid_search.best_estimator_\n",
        "\n",
        "# Test set predictions for Gradient Boosting\n",
        "y_pred_gbr = best_gbr_model.predict(X_test)\n",
        "\n",
        "# RMSE for Gradient Boosting\n",
        "gbr_rmse = np.sqrt(mean_squared_error(y_test, y_pred_gbr))\n",
        "print(\"Gradient Boosting:\")\n",
        "print(\"Best Parameters:\", best_gbr_params)\n",
        "print(f\"Test RMSE: {gbr_rmse:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjMXsvxUk-qx",
        "outputId": "8ccd100c-d31e-4a0d-b74e-91fc334c843b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV] END ..............................regressor__alpha=0.01; total time=   1.1s\n",
            "[CV] END ..............................regressor__alpha=0.01; total time=   1.2s\n",
            "[CV] END ..............................regressor__alpha=0.01; total time=   1.7s\n",
            "[CV] END ..............................regressor__alpha=0.01; total time=   1.7s\n",
            "[CV] END ..............................regressor__alpha=0.01; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=0.1; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=0.1; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=0.1; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=0.1; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=0.1; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=1.0; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=1.0; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=1.0; total time=   1.0s\n",
            "[CV] END ...............................regressor__alpha=1.0; total time=   1.1s\n",
            "[CV] END ...............................regressor__alpha=1.0; total time=   1.7s\n",
            "[CV] END ..............................regressor__alpha=10.0; total time=   1.7s\n",
            "[CV] END ..............................regressor__alpha=10.0; total time=   1.0s\n",
            "[CV] END ..............................regressor__alpha=10.0; total time=   1.0s\n",
            "[CV] END ..............................regressor__alpha=10.0; total time=   1.0s\n",
            "[CV] END ..............................regressor__alpha=10.0; total time=   1.0s\n",
            "[CV] END .............................regressor__alpha=100.0; total time=   0.9s\n",
            "[CV] END .............................regressor__alpha=100.0; total time=   0.9s\n",
            "[CV] END .............................regressor__alpha=100.0; total time=   0.9s\n",
            "[CV] END .............................regressor__alpha=100.0; total time=   1.0s\n",
            "[CV] END .............................regressor__alpha=100.0; total time=   1.0s\n",
            "[CV] END ............................regressor__alpha=1000.0; total time=   0.8s\n",
            "[CV] END ............................regressor__alpha=1000.0; total time=   1.0s\n",
            "[CV] END ............................regressor__alpha=1000.0; total time=   1.4s\n",
            "[CV] END ............................regressor__alpha=1000.0; total time=   1.4s\n",
            "[CV] END ............................regressor__alpha=1000.0; total time=   1.0s\n",
            "Ridge Regression:\n",
            "Best Parameters: {'regressor__alpha': 1.0}\n",
            "Test RMSE: 7604.03\n",
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=100; total time=  33.3s\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=100; total time=  35.6s\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=100; total time=  33.4s\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=100; total time=  34.2s\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=100; total time=  33.4s\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=200; total time= 1.1min\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=200; total time= 1.1min\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=200; total time= 1.1min\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=200; total time= 1.1min\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=200; total time= 1.1min\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=300; total time= 1.6min\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=300; total time= 1.7min\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=300; total time= 1.7min\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=300; total time= 1.6min\n",
            "[CV] END regressor__learning_rate=0.01, regressor__max_depth=3, regressor__n_estimators=300; total time= 1.6min\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=100; total time=  30.4s\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=100; total time=  30.1s\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=100; total time=  30.1s\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=100; total time=  31.0s\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=100; total time=  30.3s\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=200; total time=  57.0s\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=200; total time=  58.4s\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=200; total time=  59.2s\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=200; total time=  58.2s\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=200; total time=  58.9s\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=300; total time= 1.4min\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=300; total time= 1.5min\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=300; total time= 1.5min\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=300; total time= 1.4min\n",
            "[CV] END regressor__learning_rate=0.1, regressor__max_depth=3, regressor__n_estimators=300; total time= 1.5min\n",
            "[CV] END regressor__learning_rate=0.2, regressor__max_depth=3, regressor__n_estimators=100; total time=  29.1s\n",
            "[CV] END regressor__learning_rate=0.2, regressor__max_depth=3, regressor__n_estimators=100; total time=  29.5s\n",
            "[CV] END regressor__learning_rate=0.2, regressor__max_depth=3, regressor__n_estimators=100; total time=  30.6s\n",
            "[CV] END regressor__learning_rate=0.2, regressor__max_depth=3, regressor__n_estimators=100; total time=  29.3s\n",
            "[CV] END regressor__learning_rate=0.2, regressor__max_depth=3, regressor__n_estimators=100; total time=  29.5s\n",
            "[CV] END regressor__learning_rate=0.2, regressor__max_depth=3, regressor__n_estimators=200; total time=  57.8s\n",
            "[CV] END regressor__learning_rate=0.2, regressor__max_depth=3, regressor__n_estimators=200; total time=  59.6s\n",
            "[CV] END regressor__learning_rate=0.2, regressor__max_depth=3, regressor__n_estimators=200; total time=  58.6s\n",
            "[CV] END regressor__learning_rate=0.2, regressor__max_depth=3, regressor__n_estimators=200; total time=  58.6s\n",
            "[CV] END regressor__learning_rate=0.2, regressor__max_depth=3, regressor__n_estimators=200; total time=  59.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqQmkO4kX4Nf"
      },
      "source": [
        "### Data Understanding\n",
        "\n",
        "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Hhmk7qUX4Ng"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5LxuUVuX4Ng"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubwaFWkVX4Ng"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB5A1Rs6X4Ng"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F76anN3mX4Ng"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "After our initial exploration and fine-tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s3g14iqX4Ng"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8XdSLBBX4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP_A3jv8X4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_k-3Bt4X4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6WKfdViX4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzk_cJMbX4Nh"
      },
      "source": [
        "### Modeling\n",
        "\n",
        "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOTikeF5X4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evsHAYgqX4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GnrSUF0X4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuManut1X4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a05o8poX4Nh"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "With some modeling accomplished, we aim to reflect on what we identify as a high-quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight into drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Kke8U2hX4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBGLm9HIX4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVnO4de6X4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s96Hcj_hX4Nh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRgX_GpmX4Ni"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_S3JiltX4Ni"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq1aCJNmX4Ni"
      },
      "source": [
        "### Deployment\n",
        "\n",
        "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine-tuning their inventory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hv3XeIRX4Ni"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5uAu1VmX4Ni"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca4NIsnlX4Ni"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykO0mY1DX4Ni"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBo3REeHX4Ni"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wion9yDnX4Ni"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Frzu4I0X4Ni"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}